{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmdhV-jpngci"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL3vTUyynlEH"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gv-LfX4OnnSI"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"WeatherPrediction\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm56CnGUnw0w"
      },
      "outputs": [],
      "source": [
        "data = spark.read.csv(\"/content/Weather Data2.csv\", header=True, inferSchema=True)\n",
        "data.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1EHOaQNqRCl"
      },
      "outputs": [],
      "source": [
        "data = data.drop(\"Date/Time\")\n",
        "data.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cGNK8NYrSDo"
      },
      "outputs": [],
      "source": [
        "data.groupBy('Weather').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tjzwG2MOrlUj"
      },
      "outputs": [],
      "source": [
        "#Converting categorical values to integer values (encoding)\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "stringIndex = StringIndexer(inputCols=['Weather'],\n",
        "                       outputCols=['Weather_new'])\n",
        "\n",
        "stringIndex_model = stringIndex.fit(data)\n",
        "\n",
        "data = stringIndex_model.transform(data)\n",
        "data.show(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nWfz5LMfr-3N"
      },
      "outputs": [],
      "source": [
        "data=data.drop('Weather')\n",
        "data.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3DH3fAewl7Q"
      },
      "outputs": [],
      "source": [
        "colNames = data.columns\n",
        "colNames\n",
        "for col in data.columns:\n",
        "    print(col.ljust(15), data.filter(data[col].isNull()).count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7VRfA_5wtnF"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkFiles\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.linalg import Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shE7VTQGwwrx"
      },
      "outputs": [],
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"Temp_C\", \"Dew Point Temp_C\", \"Rel Hum_%\", \"Wind Speed_km/h\", \"Visibility_km\", \"Press_kPa\"],\n",
        "    outputCol=\"features_\")\n",
        "\n",
        "data_for_lin_reg = assembler.transform(data)\n",
        "final_data = data_for_lin_reg.select(\"features_\", \"Weather_new\")\n",
        "\n",
        "train_data, test_data = final_data.randomSplit([0.8, 0.2], seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8RvESoSw9oN"
      },
      "outputs": [],
      "source": [
        "lr = LinearRegression(featuresCol=\"features_\", labelCol=\"Weather_new\", predictionCol=\"predicted_\")\n",
        "lr_model = lr.fit(train_data)\n",
        "result = lr_model.evaluate(train_data)\n",
        "print(result.r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_refaFQ-sOkc"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkFiles\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgyJ2Ea-0YoY"
      },
      "outputs": [],
      "source": [
        "df=data.withColumnRenamed('Weather_new','Weather_new-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Esjrq_Csniq"
      },
      "outputs": [],
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"Temp_C\", \"Dew Point Temp_C\", \"Rel Hum_%\", \"Wind Speed_km/h\", \"Visibility_km\", \"Press_kPa\"],\n",
        "    outputCol=\"features\")\n",
        "data = assembler.transform(df)\n",
        "final_data = data.select(\"features\", \"Weather_new-1\")\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1yQeiGUtG5s"
      },
      "outputs": [],
      "source": [
        "print('Total train data - ',train_data.count())\n",
        "train_data.show(5)\n",
        "train_data.groupBy('Weather_new-1').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHmkmqoLtG28"
      },
      "outputs": [],
      "source": [
        "print('Total test data - ',test_data.count())\n",
        "test_data.show(5)\n",
        "test_data.groupBy('Weather_new-1').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPgFOCCxtG0E"
      },
      "outputs": [],
      "source": [
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Weather_new-1\")\n",
        "lr_model = lr.fit(train_data)\n",
        "result = lr_model.evaluate(train_data)\n",
        "print(result.r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGT1ZljmtGuq"
      },
      "outputs": [],
      "source": [
        "unleveled_data = test_data.select('features')\n",
        "unleveled_data.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-8fIMFctGsK"
      },
      "outputs": [],
      "source": [
        "predictions = lr_model.transform(unleveled_data)\n",
        "predictions.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7RqkxWjtGpb"
      },
      "outputs": [],
      "source": [
        "predictions = lr_model.transform(test_data)\n",
        "\n",
        "evaluator = RegressionEvaluator(labelCol=\"Weather_new-1\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data: {:.3f}\".format(rmse))\n",
        "\n",
        "evaluator_mse = RegressionEvaluator(labelCol=\"Weather_new-1\", metricName=\"mse\")\n",
        "mse = evaluator_mse.evaluate(predictions)\n",
        "print(\"MSE on test data: {:.3f}\".format(mse))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGmK5auAtGmj"
      },
      "outputs": [],
      "source": [
        "coefficients = lr_model.coefficients\n",
        "intercept = lr_model.intercept\n",
        "\n",
        "print(\"Coefficients: \", coefficients)\n",
        "print(\"Intercept: {:.3f}\".format(intercept))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaTtIugw11Nw"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjxLYPjs1v7l"
      },
      "outputs": [],
      "source": [
        "#from pyspark.ml.classification import LogisticRegression\n",
        "#log_reg = LogisticRegression(labelCol='Weather_new-1').fit(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fr7zy_p2Bih"
      },
      "outputs": [],
      "source": [
        "#result = log_reg.evaluate(test_data).predictions\n",
        "#result.show(40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SROb-0aK1v49"
      },
      "outputs": [],
      "source": [
        "#result.select('Weather_new-1','prediction').show(40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJMKfvqj3Pvr"
      },
      "source": [
        "DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O99xwTyy1v3k"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"Weather_new-1\")\n",
        "\n",
        "dt_model = dt.fit(train_data)\n",
        "pred = dt_model.transform(test_data)\n",
        "evaluator.evaluate(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p28ouREW1vz9"
      },
      "outputs": [],
      "source": [
        "Temp = float(input(\"Temp_C: \"))\n",
        "Dew_Point = float(input(\"Dew Point Temp_C: \"))\n",
        "Relative_Humidity = float(input(\"Rel Hum_%: \"))\n",
        "Wind_Speed = float(input(\"Wind Speed_km/h: \"))\n",
        "Visibility = float(input(\"Visibility_km: \"))\n",
        "Pressure = float(input(\"Press_kPa: \"))\n",
        "# -22.8,  -28.0,  62,  9, 25.0, 102.37\n",
        "# -21.2,   -26.8,  61, 11, 25.0, 101.81\n",
        "single_row_data = [(Temp,Dew_Point,Relative_Humidity,Wind_Speed,Visibility,Pressure)]\n",
        "single_row_df = spark.createDataFrame(single_row_data, [\"Temp_C\", \"Dew Point Temp_C\", \"Rel Hum_%\", \"Wind Speed_km/h\", \"Visibility_km\", \"Press_kPa\"])\n",
        "\n",
        "# Use the same VectorAssembler to transform the single row\n",
        "single_row_df = assembler.transform(single_row_df)\n",
        "\n",
        "# Make a prediction on the single row\n",
        "prediction = log_reg.transform(single_row_df)\n",
        "\n",
        "# Show the prediction\n",
        "prediction.select(\"features\", \"prediction\").show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}